{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Coursework 1 Coding Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialise condition for question a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([1, 2, 3, 4])\n",
    "data_y = np.array([3, 2, 0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(x, degree):\n",
    "    return np.array([x**i for i in range(degree + 1)]).T\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "x_plot = np.linspace(0, 5, 500)\n",
    "\n",
    "for degree in range(0, 4):\n",
    "    X = extract_features(data_x, degree)\n",
    "    coeffs = linear_regression(X, data_y).round(2)\n",
    "    X_plot = extract_features(x_plot, degree)\n",
    "    y_plot = X_plot @ coeffs\n",
    "    plt.plot(x_plot, y_plot, label=f'k={degree}')\n",
    "\n",
    "plt.scatter(data_x, data_y, color='red', label='Data Points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-5, 10)\n",
    "plt.title('Polynomial Fits for Different Degrees')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(0, 4):\n",
    "    X = extract_features(data_x, degree)\n",
    "    coeffs = linear_regression(X, data_y).round(2)\n",
    "    print(f\"Degree {degree+1} polynomial coefficients: {coeffs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(0, 4):\n",
    "    X = extract_features(data_x, degree)\n",
    "    coeffs = linear_regression(X, data_y)\n",
    "    coeffs = coeffs.round(2)\n",
    "    y_pred = X @ coeffs\n",
    "    print(y_pred)\n",
    "    mse = np.mean((data_y - y_pred) ** 2)\n",
    "    print(f\"MSE for k={degree}: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2a i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_sigma(x, sigma):\n",
    "    noise = np.random.normal(0, sigma, size=len(x))\n",
    "    return np.sin(2 * np.pi * x)**2 + noise\n",
    "\n",
    "# 生成数据并绘图\n",
    "np.random.seed(0)\n",
    "x_sample = np.random.uniform(0,1,30)\n",
    "y_sample = g_sigma(x_sample, sigma=0.07)\n",
    "\n",
    "x_plot = np.linspace(0, 1, 500)\n",
    "y_plot = np.sin(2 * np.pi * x_plot)**2\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_plot, y_plot, label='sin^2(2πx)')\n",
    "plt.scatter(x_sample, y_sample, color='red', label='Noisy Data Points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Function with Noise')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2a ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [2, 5, 10, 14, 18]\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_plot = np.linspace(0, 1, 500)\n",
    "for degree in degrees:\n",
    "    X = extract_features(x_sample, degree-1)\n",
    "    coeffs = linear_regression(X, y_sample)\n",
    "    X_plot = extract_features(x_plot, degree-1)\n",
    "    y_plot = X_plot @ coeffs\n",
    "    print(coeffs)\n",
    "    plt.plot(x_plot, y_plot, label=f'k={degree}')\n",
    "\n",
    "\n",
    "plt.scatter(x_sample, y_sample, color='red', label='Data Points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Polynomial Fits for Different Degrees')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_errors = []\n",
    "degrees = [i for i in range(1,19)]\n",
    "for degree in range(0,18):\n",
    "    X = extract_features(x_sample, degree)\n",
    "    coeffs = linear_regression(X, y_sample)\n",
    "    y_pred = X @ coeffs\n",
    "    mse = np.mean((y_sample-y_pred)**2)\n",
    "    training_errors.append(mse)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, np.log(training_errors), marker='o')\n",
    "plt.xlabel('Polynomial Dimension (k)')\n",
    "plt.ylabel('ln(MSE)')\n",
    "plt.title('Log Training Error vs Polynomial Dimension')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(training_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_test = np.random.uniform(0,1,1000)\n",
    "y_test = g_sigma(x_test, sigma=0.07)\n",
    "\n",
    "testing_errors = []\n",
    "degrees = [i for i in range(1,19)]\n",
    "for degree in range(0,18):\n",
    "    X = extract_features(x_sample, degree)\n",
    "    coeffs = linear_regression(X, y_sample)\n",
    "    X = extract_features(x_test, degree)\n",
    "    y_pred = X @ coeffs\n",
    "    mse = np.mean((y_test-y_pred)**2)\n",
    "    testing_errors.append(mse)\n",
    "for i in testing_errors:\n",
    "    print(i)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, np.log(testing_errors), marker='o')\n",
    "plt.xlabel('Polynomial Dimension (k)')\n",
    "plt.ylabel('ln(MSE)')\n",
    "plt.title('Log Testing Error vs Polynomial Dimension')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_testing_errors = [0 for i in range(18)]\n",
    "for experiment in range(100):\n",
    "    np.random.seed(experiment)\n",
    "    sub_x_sample = np.random.uniform(0,1,30)\n",
    "    sub_y_sample = g_sigma(sub_x_sample, sigma=0.07)\n",
    "    for degree in range(0,18):\n",
    "        X = extract_features(sub_x_sample, degree)\n",
    "        coeffs = linear_regression(X, sub_y_sample)\n",
    "        X = extract_features(x_test, degree)\n",
    "        y_pred = X @ coeffs\n",
    "        mse = np.mean((y_test-y_pred)**2)\n",
    "        testing_errors.append(mse)\n",
    "    total_testing_errors  = [x + y for x, y in zip(total_testing_errors, testing_errors)]\n",
    "average_testing_errors = [x/100 for x in total_testing_errors]\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in average_testing_errors:\n",
    "    print(i)\n",
    "plt.plot([i for i in range(1,19)], np.log(average_testing_errors), marker='o')\n",
    "plt.xlabel('Polynomial Dimension (k)')\n",
    "plt.ylabel('ln(avg MSE)')\n",
    "plt.title('Log Average Testing Error vs Polynomial Dimension')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_trig(x, degree):\n",
    "    return np.column_stack([np.sin((i + 1) * np.pi * x) for i in range(degree)])\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "x_test = np.random.uniform(0, 1, 1000)\n",
    "y_test = g_sigma(x_test, sigma=0.07)\n",
    "\n",
    "\n",
    "n_experiments = 100 \n",
    "degrees = [i for i in range(1, 19)]  \n",
    "\n",
    "x_sample = np.random.uniform(0, 1, 50)\n",
    "y_sample = g_sigma(x_sample, sigma=0.07)\n",
    "\n",
    "testing_errors = []\n",
    "\n",
    "for degree in degrees:\n",
    "    X_train = extract_features_trig(x_sample, degree)\n",
    "    coeffs = linear_regression(X_train, y_sample)\n",
    "    \n",
    "    X_test = extract_features_trig(x_test, degree)\n",
    "    y_pred = X_test @ coeffs\n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    testing_errors.append(mse)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, np.log(testing_errors), marker='o')\n",
    "plt.xlabel('Basis Dimension (k)')\n",
    "plt.ylabel('ln(MSE)')\n",
    "plt.title('Log Testing Error vs Basis Dimension (Trig Basis)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testing_errors_all = []\n",
    "\n",
    "for experiment in range(n_experiments):\n",
    "   \n",
    "    x_sample = np.random.uniform(0, 1, 50)\n",
    "    y_sample = g_sigma(x_sample, sigma=0.07)\n",
    "  \n",
    "    testing_errors = []\n",
    "    \n",
    "    for degree in degrees:\n",
    "       \n",
    "        X_train = extract_features_trig(x_sample, degree)\n",
    "        coeffs = linear_regression(X_train, y_sample)\n",
    "        \n",
    "        # 提取测试特征并计算误差\n",
    "        X_test = extract_features_trig(x_test, degree)\n",
    "        y_pred = X_test @ coeffs\n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        testing_errors.append(mse)\n",
    "    \n",
    "    =\n",
    "    testing_errors_all.append(testing_errors)\n",
    "\n",
    "average_testing_errors = np.mean(testing_errors_all, axis=0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, np.log(average_testing_errors), marker='o')\n",
    "plt.xlabel('Basis Dimension (k)')\n",
    "plt.ylabel('ln(avg MSE)')\n",
    "plt.title('Log Average Testing Error vs Basis Dimension (Trig Basis)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
